from typing import TypedDict, List
from langgraph.graph import StateGraph, END
from langchain_openai import ChatOpenAI
from langchain_core.prompts import ChatPromptTemplate
from dotenv import load_dotenv
from .rag import resume_retriever, culture_retriever

load_dotenv()

# --- 1. å®šç¾© ---
# LLMã®æº–å‚™
llm = ChatOpenAI(model="gpt-4o", temperature=0.7)

# ã‚¹ãƒ†ãƒ¼ãƒˆï¼ˆä¼šè©±ã®çŠ¶æ…‹ï¼‰ã®å®šç¾©
class AgentState(TypedDict):
    question: str       # ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®è³ªå•
    context_data: str   # æ¤œç´¢ã—ãŸè‡ªåˆ†ã®çµŒæ­´
    draft: str          # æœ€åˆã®å›ç­”æ¡ˆ
    critique: str       # DeNAäººäº‹ã‹ã‚‰ã®ãƒ€ãƒ¡å‡ºã—
    final_answer: str   # æœ€çµ‚å›ç­”
    logs: List[str]     # ãƒ•ãƒ­ãƒ³ãƒˆã«è¡¨ç¤ºã™ã‚‹æ€è€ƒãƒ­ã‚°

# --- 2. ãƒãƒ¼ãƒ‰ï¼ˆå‡¦ç†æ‹…å½“è€…ï¼‰ã®å®šç¾© ---

# Agent A: è‡ªåˆ†å°‚é–€å®¶ï¼ˆäº‹å®Ÿã‚’é›†ã‚ã¦å›ç­”æ¡ˆã‚’ä½œã‚‹ï¼‰
def candidate_node(state: AgentState):
    question = state["question"]
    # è‡ªåˆ†ã®çµŒæ­´ã‚’æ¤œç´¢
    docs = resume_retriever.invoke(question)
    context_text = "\n".join([d.page_content for d in docs])
    
    prompt = ChatPromptTemplate.from_template(
        "ã‚ãªãŸã¯å°±è·æ´»å‹•ä¸­ã®ã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢å­¦ç”Ÿã§ã™ã€‚ä»¥ä¸‹ã®äº‹å®Ÿæƒ…å ±ã«åŸºã¥ã„ã¦ã€è³ªå•ã¸ã®å›ç­”æ¡ˆã‚’ä½œæˆã—ã¦ãã ã•ã„ã€‚\n"
        "äº‹å®Ÿ: {context}\nè³ªå•: {question}\nå›ç­”æ¡ˆ:"
    )
    chain = prompt | llm
    response = chain.invoke({"context": context_text, "question": question})
    
    log = f"ğŸ¤– Candidate Agent: è³ªå•ã€Œ{question}ã€ã«é–¢é€£ã™ã‚‹çµŒé¨“ã‚’æ¤œç´¢ã—ã€ãƒ‰ãƒ©ãƒ•ãƒˆã‚’ä½œæˆã—ã¾ã—ãŸã€‚"
    return {"context_data": context_text, "draft": response.content, "logs": [log]}

# Agent B: DeNAã‚«ãƒ«ãƒãƒ£ãƒ¼æ‹…å½“ï¼ˆãƒ€ãƒ¡å‡ºã—ã‚’ã™ã‚‹ï¼‰
def culture_node(state: AgentState):
    draft = state["draft"]
    # DeNAã®æ–‡åŒ–ã‚’æ¤œç´¢ï¼ˆå…¨ä»¶å–å¾—ã«è¿‘ã„å½¢ã§DeNAã‚‰ã—ã•ã‚’æ³¨å…¥ï¼‰
    docs = culture_retriever.invoke("DeNA Promise Delight")
    culture_text = "\n".join([d.page_content for d in docs])
    
    prompt = ChatPromptTemplate.from_template(
        "ã‚ãªãŸã¯æ ªå¼ä¼šç¤¾DeNAã®æ¡ç”¨æ‹…å½“ãƒãƒãƒ¼ã‚¸ãƒ£ãƒ¼ã§ã™ã€‚ä»¥ä¸‹ã®å›ç­”æ¡ˆã‚’å³ã—ããƒã‚§ãƒƒã‚¯ã—ã¦ãã ã•ã„ã€‚\n"
        "åŸºæº–: {culture}\n"
        "ç‰¹ã«ã€ŒDelightï¼ˆé©šãï¼‰ã€ã€Œã‚³ãƒˆã«å‘ã‹ã†ï¼ˆæˆæœæ€è€ƒï¼‰ã€ã®è¦³ç‚¹ãŒè¶³ã‚Šã¦ã„ã‚‹ã‹ç¢ºèªã—ã€"
        "è¶³ã‚Šãªã„å ´åˆã¯å…·ä½“çš„ã«ã©ã®ã‚ˆã†ã«ä¿®æ­£ã™ã¹ãã‹ã€ç°¡æ½”ã«æŒ‡æ‘˜ã—ã¦ãã ã•ã„ã€‚\n"
        "å›ç­”æ¡ˆ: {draft}\næŒ‡æ‘˜ã‚³ãƒ¡ãƒ³ãƒˆ:"
    )
    chain = prompt | llm
    response = chain.invoke({"culture": culture_text, "draft": draft})
    
    log = f"ğŸ¢ DeNA HR Agent: å›ç­”æ¡ˆã‚’ãƒ¬ãƒ“ãƒ¥ãƒ¼ä¸­... DeNAã®ä¾¡å€¤è¦³ï¼ˆDelightç­‰ï¼‰ã¨ç…§ã‚‰ã—åˆã‚ã›ã€æ”¹å–„ç‚¹ã‚’æŒ‡æ‘˜ã—ã¾ã™ã€‚"
    return {"critique": response.content, "logs": [log]}

# Agent C: æœ€çµ‚èª¿æ•´æ‹…å½“ï¼ˆæ›¸ãç›´ã™ï¼‰
def writer_node(state: AgentState):
    draft = state["draft"]
    critique = state["critique"]
    
    prompt = ChatPromptTemplate.from_template(
        "æŒ‡æ‘˜äº‹é …ã‚’è¸ã¾ãˆã¦ã€å›ç­”æ¡ˆã‚’æœ€é«˜ã®ã‚‚ã®ã«æ›¸ãç›´ã—ã¦ãã ã•ã„ã€‚\n"
        "å…ƒã®æ¡ˆ: {draft}\næŒ‡æ‘˜: {critique}\n"
        "ä¿®æ­£å¾Œã®å›ç­”ï¼ˆä¸å¯§ã‹ã¤ç†±æ„ã‚’æŒã£ã¦ï¼‰:"
    )
    chain = prompt | llm
    response = chain.invoke({"draft": draft, "critique": critique})
    
    log = f"âœï¸ Writer Agent: æŒ‡æ‘˜ã‚’å—ã‘ã€DeNAã‚«ãƒ«ãƒãƒ£ãƒ¼ã«ãƒ•ã‚£ãƒƒãƒˆã™ã‚‹ã‚ˆã†ã«å›ç­”ã‚’ãƒ–ãƒ©ãƒƒã‚·ãƒ¥ã‚¢ãƒƒãƒ—ã—ã¾ã—ãŸã€‚"
    return {"final_answer": response.content, "logs": [log]}

# --- 3. ã‚°ãƒ©ãƒ•ã®æ§‹ç¯‰ ---
workflow = StateGraph(AgentState)

workflow.add_node("candidate", candidate_node)
workflow.add_node("hr_review", culture_node)
workflow.add_node("writer", writer_node)

workflow.set_entry_point("candidate")
workflow.add_edge("candidate", "hr_review")
workflow.add_edge("hr_review", "writer")
workflow.add_edge("writer", END)

# ã‚³ãƒ³ãƒ‘ã‚¤ãƒ«
app_graph = workflow.compile()